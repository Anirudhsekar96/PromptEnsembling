# PromptEnsembling

Creating optimized prompt ensembles using dspy
[dspy_starter.ipynb](Notebooks/dspy_starter.ipynb) contains examples for QA, Chain of Thought Reasoning, RAG, MultiHop CoT and MultiHop CoT with RAG. The models used are gpt-3.5-turbo as language model and colbertv2 as retreival model

[OpenAi_starter.ipynb](Notebooks/OpenAi_starter.ipynb) contains examples of OpenAi API access for Text Genreation, Text Generation with expect output formatting e.g. JSON and embedding extraction. The models used are: gpt-3.5 and gpt-4

[QA_Local_Ensemble.ipynb](Notebooks/QA_Local_Ensemble.ipynb) contains an example of LLM output stacking to obtain better QA results. The models used are: gpt2, roberta, tiny_bert and Amazon_QANLU

[Text_Generation_Local_Ensemble.ipynb](Notebooks/Text_Generation_Local_Ensemble.ipynb) contains an example of stacking text genreation outputs. The models used are: gpt2, tiny_llama, distil_bert and microsoft_phi2
