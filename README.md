# PromptEnsembling

Creating optimized prompt ensembles using dspy

[QA_Local_Ensemble.ipynb](Notebooks/QA_Local_Ensemble.ipynb) contains an example of LLM output stacking to obtain better QA results. The models used are: gpt2, roberta, tiny_bert and Amazon_QANLU
[Text_Generation_Local_Ensemble.ipynb](Notebooks/Text_Generation_Local_Ensemble.ipynb) contains an example of stacking text genreation outputs. The models used are: gpt2, tiny_llama, distil_bert and microsoft_phi2
